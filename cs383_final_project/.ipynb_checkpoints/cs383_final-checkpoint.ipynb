{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robert Roche\n",
    "## CS383 Final Project\n",
    "\n",
    "\n",
    "### NFL QB Prospect Rankings/Draft Order Prediction\n",
    "\n",
    "\n",
    "### The data used in this project is from kaggle.com, and modified slightly to suit the needs of the program\n",
    "\n",
    "### dataset source: https://www.kaggle.com/av8ramit/ncaa-college-quarterback-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from math import ceil\n",
    "from math import *\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 4. 7. 1. 1. 1. 1. 2. 3. 3. 4. 6. 1. 1. 1. 1. 2. 2. 3. 5. 6.\n",
      " 7. 1. 1. 2. 3. 4. 5. 6. 6. 7. 1. 1. 1. 2. 4. 1. 1. 2. 2. 3. 5. 5. 7. 1.\n",
      " 2. 2. 2. 3. 5. 6. 1. 1. 1. 2. 2. 3. 3. 4. 6. 1. 1. 1. 3. 3. 4. 5. 6. 7.\n",
      " 1. 1. 1. 3. 4. 5. 6. 7. 7. 7. 7. 1. 1. 1. 1. 3. 3. 4. 5. 6. 7. 1. 1. 1.\n",
      " 3. 4. 4. 5. 5. 2. 2. 4. 4. 5. 5. 1. 3. 5. 6. 6. 6. 6. 7. 7. 7. 1. 1. 1.\n",
      " 2. 3. 4. 4. 7. 7. 1. 1. 1. 3. 3. 4. 5. 7. 1. 1. 1. 2. 2. 4. 4. 5. 6. 1.\n",
      " 1. 1. 1.]\n",
      "[[  23.   43.  600. ...  827.   11.    0.]\n",
      " [  22.   44.  988. ...  342.    4.    0.]\n",
      " [  23.   36.  646. ... -281.    3.    0.]\n",
      " ...\n",
      " [  21.   30.  711. ... -154.    6.    0.]\n",
      " [  21.   26.  523. ...  340.    7.    0.]\n",
      " [  22.   41.  894. ...   25.   17.    0.]]\n"
     ]
    }
   ],
   "source": [
    "f = open(\"quarterback_training_mod.csv\")\n",
    "length = len(f.readline().split(','))\n",
    "\n",
    "#getting the data from our csv ignoring strings\n",
    "data=np.loadtxt(\"quarterback_training_mod.csv\", delimiter=\",\", skiprows = 1, usecols=range(1,length))\n",
    "\n",
    "#adding the names of each player to a list so we know can know who exactly we're ranking\n",
    "labels = []\n",
    "reader = csv.reader(f, delimiter=\",\")\n",
    "for i in reader:\n",
    "    labels.append(i[0])\n",
    "\n",
    "f.close()\n",
    "\n",
    "y = np.array(data[0:,11])\n",
    "print(y)\n",
    "X = np.array(data[:,0:11])\n",
    "print(X)\n",
    "\n",
    "#split the data into 2/3 trainging 1/3 testing\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = (1/3),random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_mean = np.mean(X_train, axis=0)\n",
    "tst_mean = np.mean(X_test, axis=0)\n",
    "\n",
    "trn_std = np.std(X_train, axis=0,ddof=1)\n",
    "tst_std = np.std(X_test, axis=0,ddof=1)\n",
    "\n",
    "X_train = (X_train-trn_mean)/trn_std\n",
    "X_test = (X_test-tst_mean)/tst_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg = LogisticRegression()\n",
    "\n",
    "LogReg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 7. 2. 2. 1. 3. 3. 5. 6. 1. 1. 6. 4. 6. 7. 6. 1. 1. 4. 1. 4. 2. 1. 1.\n",
      " 1. 7. 1. 5. 1. 5. 4. 1. 5. 2. 5. 3. 1. 2. 5. 1. 3. 6. 4. 1. 4. 2. 7. 4.\n",
      " 1.]\n",
      "[1. 5. 1. 1. 1. 7. 7. 3. 7. 1. 1. 7. 2. 2. 1. 7. 7. 7. 7. 5. 7. 2. 1. 2.\n",
      " 1. 1. 1. 6. 1. 6. 2. 1. 1. 7. 7. 1. 1. 1. 1. 3. 3. 3. 3. 1. 7. 1. 1. 3.\n",
      " 1.]\n",
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "y_pred=LogReg.predict(X_test)\n",
    "print(y_test)\n",
    "\n",
    "print(y_pred)\n",
    "print(LogReg.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
